{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "#import random\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "#import matplotlib.pyplot as plt\n",
    "from numpy import nan as Nan\n",
    "#import psycopg2\n",
    "import sqlalchemy as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import import_ipynb\n",
    "#import python_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from python_final import popularity,interaction_customer_per_item,service_details_vectors,get_item_profile,get_item_profiles,build_users_profile,build_users_profiles,get_items_interacted,content_based_recommender,collaborative_based_recommender,Hybrid_recommender,last_purchase_model,get_users_interacted,get_interested_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity(system_default_df,customer_interactions,topn):#one time\n",
    "    \n",
    "    required_interactions=customer_interactions.copy()\n",
    "    if 'rating' in customer_interactions:\n",
    "        if 'comment' in customer_interactions:\n",
    "            required_interactions.remove('comment')\n",
    "        popularity_columns=['service_id','service_name']+required_interactions.copy()\n",
    "        popularity_df= system_default_df[popularity_columns].copy()\n",
    "        popularity_df['avg_rating']=np.where(popularity_df.rating.notnull(),popularity_df.purchased*popularity_df.rating,Nan)\n",
    "        transit_columns=popularity_columns.copy() #\n",
    "        transit_columns.append('avg_rating')#\n",
    "        transit_columns.remove('service_name')#\n",
    "        popularity_df[transit_columns]=popularity_df[transit_columns].apply(pd.to_numeric)\n",
    "        popularity_df['rated_purchases']=np.where(popularity_df['rating'].notnull(),popularity_df['purchased'],0)\n",
    "        transit_columns.append('rated_purchases')#\n",
    "        new_df1=popularity_df.dropna()\n",
    "        transit_columns.remove('service_id')#\n",
    "        new_df2=new_df1.groupby(['service_id'])[transit_columns].sum().reset_index()\n",
    "        net_avg_rating=new_df2['avg_rating'].sum()/new_df2['rated_purchases'].sum()\n",
    "        new_df2['avg_rating']=new_df2['avg_rating']/new_df2['rated_purchases']\n",
    "        transit_columns.remove('avg_rating')#\n",
    "        transit_columns.remove('rating')#\n",
    "        popularity_df=popularity_df.groupby(['service_id'])[transit_columns].sum().reset_index()\n",
    "        popularity_df=pd.merge(popularity_df,new_df2[['avg_rating','service_id']],on='service_id',how='left')\n",
    "        enteraction_total=popularity_df[transit_columns].sum().sum()\n",
    "        popularity_df['interaction_strength']=0\n",
    "        for z in transit_columns:\n",
    "            popularity_df[z]=popularity_df[z].apply(lambda x: x*math.log(1+enteraction_total/popularity_df[z].sum(),2))\n",
    "            if (z!='rated_purchases') and (z!='avg_rating') and (z!='dislike'):\n",
    "                popularity_df['interaction_strength']=popularity_df['interaction_strength']+popularity_df[z]\n",
    "            if z=='dislike':\n",
    "                popularity_df['interaction_strength']=popularity_df['interaction_strength']-popularity_df[z]\n",
    "        popularity_df['avg_rating']=popularity_df['avg_rating'].apply(lambda x: x-net_avg_rating)\n",
    "        popularity_df['avg_rating'].fillna(0,inplace=True) \n",
    "        popularity_df['interaction_strength']=popularity_df['interaction_strength']+popularity_df['rated_purchases']*popularity_df['avg_rating']\n",
    "        popularity_df = popularity_df.sort_values(by=['interaction_strength'], ascending=False)\n",
    "        system_default_df['service_id'] = pd.to_numeric(system_default_df['service_id'])\n",
    "        popularity_df = pd.merge(system_default_df[['service_id','service_name']],popularity_df,on='service_id')\n",
    "        popularity_df=popularity_df.drop_duplicates(['service_id'], keep='last')\n",
    "        return popularity_df[['service_id','service_name']].head(topn).reset_index(drop=True)\n",
    "    else:\n",
    "        if 'comment' in customer_interactions:\n",
    "            required_interactions.remove('comment')\n",
    "        popularity_columns=['service_id','service_name']+required_interactions.copy()\n",
    "        popularity_df= system_default_df[popularity_columns].copy()\n",
    "        popularity_df[required_interactions]=popularity_df[required_interactions].apply(pd.to_numeric)\n",
    "        new_df=popularity_df.groupby(['service_id','service_name'])[required_interactions].sum().reset_index()\n",
    "        interaction_total=new_df[required_interactions].sum().sum()\n",
    "        new_df['interaction_strength']=0\n",
    "        for z in required_interactions:\n",
    "            new_df[z]=new_df[z].apply(lambda x: x*math.log(1+interaction_total/new_df[z].sum(),2))\n",
    "            if z!='dislike':\n",
    "                new_df['interaction_strength']=new_df['interaction_strength']+new_df[z]\n",
    "            else:\n",
    "                new_df['interaction_strength']=new_df['interaction_strength']-new_df[z]\n",
    "        new_df = new_df.sort_values(by=['interaction_strength'], ascending=False)    \n",
    "        return new_df[['service_id','service_name']].head(topn).reset_index(drop=True)\n",
    "\n",
    "def interaction_customer_per_item(system_default_df,customer_interactions):#one time\n",
    "    required_interactions=customer_interactions.copy()\n",
    "    if 'rating' in customer_interactions:\n",
    "        if 'comment' in customer_interactions:\n",
    "            required_interactions.remove('comment')     \n",
    "        popularity_columns=['service_id','service_name']+required_interactions.copy()\n",
    "        popularity_columns.append('customer_id')\n",
    "        popularity_df= system_default_df[popularity_columns].copy()\n",
    "        popularity_df['avg_rating']=np.where(popularity_df.rating.notnull(),popularity_df.purchased*popularity_df.rating,Nan)\n",
    "        transit_columns=popularity_columns.copy() #\n",
    "        transit_columns.append('avg_rating')#\n",
    "        transit_columns.remove('service_name')#\n",
    "        popularity_df[transit_columns]=popularity_df[transit_columns].apply(pd.to_numeric)\n",
    "        popularity_df['rated_purchases']=np.where(popularity_df['rating'].notnull(),popularity_df['purchased'],0)\n",
    "        transit_columns.append('rated_purchases')#\n",
    "        new_df1=popularity_df.dropna()\n",
    "        transit_columns.remove('service_id')#\n",
    "        transit_columns.remove('customer_id')\n",
    "        new_df2=new_df1.groupby(['service_id','customer_id'])[transit_columns].sum().reset_index()\n",
    "        net_avg_rating=new_df2['avg_rating'].sum()/new_df2['rated_purchases'].sum()\n",
    "        new_df2['avg_rating']=new_df2['avg_rating']/new_df2['rated_purchases']\n",
    "        transit_columns.remove('avg_rating')#\n",
    "        transit_columns.remove('rating')#\n",
    "        popularity_df=popularity_df.groupby(['service_id','customer_id'])[transit_columns].sum().reset_index()\n",
    "        popularity_df=pd.merge(popularity_df,new_df2[['avg_rating','service_id','customer_id']],on=['service_id','customer_id'],how='left')\n",
    "        enteraction_total=popularity_df[transit_columns].sum().sum()\n",
    "        popularity_df['interaction_strength']=0\n",
    "        for z in transit_columns:\n",
    "            popularity_df[z]=popularity_df[z].apply(lambda x: x*math.log(1+enteraction_total/popularity_df[z].sum(),2))\n",
    "            if (z!='rated_purchases') and (z!='avg_rating') and (z!='dislike'):\n",
    "                popularity_df['interaction_strength']=popularity_df['interaction_strength']+popularity_df[z]\n",
    "            if z=='dislike':\n",
    "                popularity_df['interaction_strength']=popularity_df['interaction_strength']-popularity_df[z]\n",
    "        popularity_df['avg_rating']=popularity_df['avg_rating'].apply(lambda x: x-net_avg_rating)\n",
    "        popularity_df['avg_rating'].fillna(0,inplace=True)    \n",
    "        popularity_df['interaction_strength']=popularity_df['interaction_strength']+popularity_df['rated_purchases']*popularity_df['avg_rating']\n",
    "        popularity_df = popularity_df.sort_values(by=['customer_id'])\n",
    "        popularity_df = popularity_df[['service_id','customer_id','interaction_strength']]\n",
    "        popularity_df['interaction_strength']=popularity_df['interaction_strength'].apply(lambda x:math.log(1+x,2))\n",
    "        return popularity_df\n",
    "    else :\n",
    "        if 'comment' in customer_interactions:\n",
    "            required_interactions.remove('comment')\n",
    "        popularity_columns=['service_id','service_name']+required_interactions.copy()\n",
    "        popularity_columns.append('customer_id')\n",
    "        popularity_df= system_default_df[popularity_columns].copy()\n",
    "        popularity_df[required_interactions]=popularity_df[required_interactions].apply(pd.to_numeric)\n",
    "        new_df=popularity_df.groupby(['service_id','service_name','customer_id'])[required_interactions].sum().reset_index()\n",
    "        interaction_total=new_df[required_interactions].sum().sum()\n",
    "        new_df['interaction_strength']=0\n",
    "        for z in required_interactions:\n",
    "            new_df[z]=new_df[z].apply(lambda x: x*math.log(1+interaction_total/new_df[z].sum(),2))\n",
    "            if z!='dislike':\n",
    "                new_df['interaction_strength']=new_df['interaction_strength']+new_df[z]\n",
    "            else:    \n",
    "                new_df['interaction_strength']=new_df['interaction_strength']-new_df[z]\n",
    "        new_df = new_df.sort_values(by=['customer_id'])    \n",
    "        new_df = new_df[['service_id','customer_id','interaction_strength']]\n",
    "        new_df['interaction_strength']=new_df['interaction_strength'].apply(lambda x:math.log(1+x,2))\n",
    "        return new_df\n",
    "    \n",
    "def service_details_vectors(system_default_df,service_details):#one time \n",
    "    DF=system_default_df[service_details].drop_duplicates()\n",
    "    DF=DF.reset_index(drop=True)\n",
    "    required_details = service_details.copy()\n",
    "    required_details.remove('service_id')\n",
    "    DF['text']=\"\"\n",
    "    for x in required_details:\n",
    "        DF['text']=DF['text']+DF[x]+\" \"\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                     ngram_range=(1, 2),\n",
    "                     min_df=0.003,\n",
    "                     max_df=0.5,\n",
    "                     max_features=5000,\n",
    "                     stop_words=stopwords_list)\n",
    "    tfidf_matrix = vectorizer.fit_transform(DF['text'])\n",
    "    tfidf_feature_names = vectorizer.get_feature_names()\n",
    "    vect= tfidf_matrix.toarray()\n",
    "    my_df=pd.DataFrame(vect,columns=tfidf_feature_names)\n",
    "    my_df=pd.merge(DF[['service_id']],my_df,left_index=True,right_index=True)\n",
    "    my_df.set_index('service_id',inplace=True)\n",
    "    return tfidf_matrix,my_df\n",
    "\n",
    "def get_item_profile(item_id,dataframe): #basically get the vector profile of a particular item\n",
    "    my_item_profile=np.asarray(dataframe.loc[item_id])\n",
    "    return my_item_profile\n",
    "\n",
    "def get_item_profiles(ids,dataframe):#basically get the vector profile of a particular list of items\n",
    "    item_profiles_list = [get_item_profile(x,dataframe) for x in ids]\n",
    "    my_item_profiles_list=np.asarray(item_profiles_list)\n",
    "    return my_item_profiles_list\n",
    "\n",
    "def build_users_profile(customer_id, test_df,dataframe):\n",
    "    interactions_person_df =test_df[test_df['customer_id']==customer_id]\n",
    "    mylist=interactions_person_df['service_id'].tolist()\n",
    "    if isinstance(mylist, list)==False:\n",
    "        mylist=[]\n",
    "        mylist.append(interactions_person_df['service_id'].tolist())\n",
    "    user_item_profiles = get_item_profiles(mylist,dataframe)\n",
    "    user_item_strengths = np.array(interactions_person_df['interaction_strength']).reshape(-1,1)\n",
    "    user_item_strengths_weighted_avg = np.sum(np.multiply(user_item_profiles,user_item_strengths), axis=0) / np.sum(user_item_strengths)\n",
    "    user_profile_norm=user_item_strengths_weighted_avg / np.linalg.norm(user_item_strengths_weighted_avg)\n",
    "    return user_profile_norm\n",
    "\n",
    "def build_users_profiles(test_df,dataframe): \n",
    "    interactions_indexed_df = test_df.set_index('customer_id')\n",
    "    user_profiles = {}\n",
    "    for customer_id in interactions_indexed_df.index.unique():\n",
    "        user_profiles[customer_id] = build_users_profile(customer_id, test_df,dataframe)\n",
    "    return user_profiles\n",
    "\n",
    "def get_items_interacted(person_id,system_default_df,interactions_df,ignore_previously_interacted_items,ignore_previously_purchased_items):#repeat\n",
    "    # Get the user's data and merge in the movie information.\n",
    "    interacted_items = []\n",
    "    if ignore_previously_interacted_items==True:\n",
    "        interacted_items = interactions_df.loc[person_id]['service_id'].tolist()\n",
    "        return interacted_items\n",
    "    if ignore_previously_purchased_items==True:\n",
    "        poop=system_default_df.groupby(['customer_id','service_id'])[['purchased']].sum().reset_index()\n",
    "        poop=poop[poop['purchased']!=0]\n",
    "        poop.set_index('customer_id',inplace=True)\n",
    "        interacted_items = poop.loc[person_id]['service_id'].tolist()\n",
    "        return interacted_items\n",
    "    return interacted_items\n",
    "\n",
    "def content_based_recommender(customer_id,user_profiles,tfidf_matrix,system_default_df,test_df,ignore_previously_interacted_items,ignore_previously_purchased_items,topn):#repeat\n",
    "    #Computes the cosine similarity between the user profile and all item profiles\n",
    "    cosine_similarities = cosine_similarity([user_profiles[customer_id]], tfidf_matrix)\n",
    "    #Gets the top similar items\n",
    "    similar_indices = cosine_similarities.argsort().flatten()\n",
    "    #Sort the similar items by similarity\n",
    "    item_ids=system_default_df['service_id'].drop_duplicates().tolist()\n",
    "    similar_items = sorted([(item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
    "    interacted_df=test_df.set_index('customer_id')\n",
    "    items_to_ignore=get_items_interacted(customer_id,system_default_df,interacted_df,ignore_previously_interacted_items,ignore_previously_purchased_items)\n",
    "    similar_items_filtered = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))        \n",
    "    recommendations_df = pd.DataFrame(similar_items_filtered, columns=['service_id', 'recStrength']) \\\n",
    "                                    .head(topn)\n",
    "    return recommendations_df\n",
    "\n",
    "def collaborative_based_recommender(customer_id,system_default_df,test_df,ignore_previously_interacted_items,ignore_previously_purchased_items,topn):\n",
    "    users_items_pivot_matrix_df = test_df.pivot(index='customer_id', \n",
    "                                            columns='service_id', \n",
    "                                            values='interaction_strength').fillna(0)\n",
    "    users_ids = list(users_items_pivot_matrix_df.index)\n",
    "    users_items_pivot_matrix = users_items_pivot_matrix_df.values\n",
    "    #The number of factors to factor the user-item matrix.\n",
    "    if min(users_items_pivot_matrix.shape)<30:     \n",
    "        NUMBER_OF_FACTORS_MF = int (min(users_items_pivot_matrix.shape)/2)\n",
    "    else:\n",
    "        NUMBER_OF_FACTORS_MF=15                       \n",
    "    #Performs matrix factorization of the original user item matrix\n",
    "    U, sigma, Vt = svds(users_items_pivot_matrix, k = NUMBER_OF_FACTORS_MF)\n",
    "    sigma = np.diag(sigma)\n",
    "    all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \n",
    "    #Converting the reconstructed matrix back to a Pandas dataframe\n",
    "    cf_preds_df = pd.DataFrame(all_user_predicted_ratings, columns = users_items_pivot_matrix_df.columns, index=users_ids).transpose()\n",
    "    # Get and sort the user's predictions\n",
    "    sorted_user_predictions = cf_preds_df[customer_id].sort_values(ascending=False).reset_index().rename(columns={customer_id: 'recStrength'})\n",
    "    # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
    "    interacted_df=test_df.set_index('customer_id')\n",
    "    items_to_ignore=get_items_interacted(customer_id,system_default_df,interacted_df,ignore_previously_interacted_items,ignore_previously_purchased_items)\n",
    "    recommendations_df = sorted_user_predictions[~sorted_user_predictions['service_id'].isin(items_to_ignore)] \\\n",
    "                               .sort_values('recStrength', ascending = False) \\\n",
    "                               .head(topn)    \n",
    "    return recommendations_df\n",
    "\n",
    "def Hybrid_recommender(customer_id,user_profiles,tfidf_matrix,system_default_df,test_df,ignore_previously_interacted_items,ignore_previously_purchased_items,topn):\n",
    "    #Getting the top-1000 Content-based filtering recommendations\n",
    "    cb_recs_df = content_based_recommender(customer_id,user_profiles,tfidf_matrix,system_default_df,test_df,ignore_previously_interacted_items,ignore_previously_purchased_items,1000).rename(columns={'recStrength': 'recStrengthCB'})        \n",
    "    #Getting the top-1000 Collaborative filtering recommendations\n",
    "    cf_recs_df = collaborative_based_recommender(customer_id,system_default_df,test_df,ignore_previously_interacted_items,ignore_previously_purchased_items,1000).rename(columns={'recStrength': 'recStrengthCF'})        \n",
    "    #Combining the results by service_id\n",
    "    recs_df = cb_recs_df.merge(cf_recs_df,\n",
    "                               how = 'inner', \n",
    "                               left_on = 'service_id', \n",
    "                               right_on = 'service_id')        \n",
    "    #Computing a hybrid recommendation score based on CF and CB scores\n",
    "    recs_df['recStrengthHybrid'] = recs_df['recStrengthCB'] * recs_df['recStrengthCF']        \n",
    "    #Sorting recommendations by hybrid score\n",
    "    recommendations_df = recs_df.sort_values('recStrengthHybrid', ascending=False).head(topn)\n",
    "    recommendations_df = pd.merge(recommendations_df[['service_id']],system_default_df[['service_id','service_name']].drop_duplicates(),on='service_id',how='left')\n",
    "    return recommendations_df.reset_index(drop=True)\n",
    "\n",
    "def last_purchase_model(customer_id,service_id,customer_details,service_details,system_default_df,user_profiles,dataframe,test_df,ignore_previously_interacted_items,ignore_previously_purchased_items,topn):\n",
    "    req_col=customer_details.copy()+service_details.copy()+['purchased']\n",
    "    recommed_df=system_default_df[req_col].copy()\n",
    "    recommed_df=recommed_df.groupby(['customer_id','service_id'])['purchased'].sum().reset_index()\n",
    "    recommed_df=recommed_df[recommed_df['purchased']!=0]\n",
    "    req_customer_ids=recommed_df[recommed_df['service_id']==service_id]['customer_id'].tolist()\n",
    "    req_customer_ids= (req_customer_ids if type(req_customer_ids)==list else [req_customer_ids])  \n",
    "    recommed_df=recommed_df[recommed_df['customer_id'].isin(req_customer_ids)]\n",
    "    recommed_df=recommed_df[recommed_df['service_id']!=service_id]\n",
    "    top_commonly_purchased=recommed_df['service_id'].value_counts().head(1000)\n",
    "    item_ids=top_commonly_purchased.index.tolist()\n",
    "    interacted_df=test_df.set_index('customer_id')\n",
    "    items_to_ignore=get_items_interacted(customer_id,system_default_df,interacted_df,ignore_previously_interacted_items,ignore_previously_purchased_items)\n",
    "    item_ids = [x for x in item_ids if x not in items_to_ignore]\n",
    "    cosine_similarities = cosine_similarity([user_profiles[customer_id]], get_item_profiles(item_ids,dataframe))\n",
    "    s = pd.Series(cosine_similarities.flatten(),index=item_ids)\n",
    "    recommendations_df =pd.DataFrame({'service_id':s.index, 'recStrength':s.values})  \n",
    "    recommendations_df=recommendations_df.sort_values(by='recStrength', ascending=False).head(topn)\n",
    "    recommendations_df = pd.merge(recommendations_df[['service_id']],system_default_df[['service_id','service_name']].drop_duplicates(),on='service_id',how='left')\n",
    "    return recommendations_df.reset_index(drop=True)\n",
    "\n",
    "def get_users_interacted(product_id,system_default_df,interactions_df,ignore_previously_interacted_users,ignore_previously_purchased_users):#repeat\n",
    "    interacted_users = []\n",
    "    if ignore_previously_interacted_users==True:\n",
    "        interacted_users = interactions_df.loc[product_id]['customer_id'].tolist()\n",
    "        return interacted_users\n",
    "    if ignore_previously_purchased_users==True:\n",
    "        poop=system_default_df.groupby(['customer_id','service_id'])[['purchased']].sum().reset_index()\n",
    "        poop=poop[poop['purchased']!=0]\n",
    "        poop.set_index('service_id',inplace=True)\n",
    "        interacted_users = poop.loc[product_id]['customer_id'].tolist()\n",
    "        return interacted_users\n",
    "    return interacted_users\n",
    "\n",
    "def get_interested_users(product_id,user_profiles,system_default_df,test_df,dataframe,ignore_previously_interacted_users,ignore_previously_purchased_users,topn):\n",
    "    users_list = user_profiles.keys()\n",
    "    interactions_df=test_df.set_index('service_id')\n",
    "    users_to_ignore=get_users_interacted(product_id,system_default_df,interactions_df,ignore_previously_interacted_users,ignore_previously_purchased_users)\n",
    "    cosine_similarities = cosine_similarity([get_item_profile(product_id,dataframe)],np.array(list(user_profiles.values())))\n",
    "    sad = pd.Series(cosine_similarities.flatten(),index=users_list)\n",
    "    sad_df = pd.DataFrame({'customer_id':sad.index, 'recStrength':sad.values})\n",
    "    sad_df = sad_df[~sad_df['customer_id'].isin(users_to_ignore)]\n",
    "    sad_df.sort_values(by='recStrength', ascending=False,inplace=True)\n",
    "    sad_df=sad_df.head(topn)\n",
    "    if 'customer_name' in system_default_df.columns:\n",
    "        sad_df=pd.merge(sad_df[['customer_id']],system_default_df[['customer_id','customer_name']].drop_duplicates(),on='customer_id',how='left')\n",
    "    else:\n",
    "        sad_df=sad_df[['customer_id']]\n",
    "    return sad_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job2(projectid,customer_search_id = None,product_search_id = None,topn=10,ignore_previously_interacted_items=True,ignore_previously_purchased_items=True,ignore_previously_interacted_users=True,ignore_previously_purchased_users=True):\n",
    "    engine = sy.create_engine('postgresql://postgres:anshul1998@localhost:5432/sample_db',echo=False)\n",
    "    system_default_df=pd.read_sql(\"SELECT * FROM myproject2 \", engine)\n",
    "    \n",
    "    default_cols=system_default_df.columns.tolist()\n",
    "    \n",
    "    customer_interactions_total=['views','bookmark','purchased','like','dislike','rating','comment','follow']\n",
    "    service_provider_details_total=['service_provider_id','service_provider_name','service_provider_rating']\n",
    "    service_details_total=['service_id','service_name','service_category','service_description']\n",
    "    customer_details_total=['customer_id','customer_name']\n",
    "    \n",
    "    popularity_model=False\n",
    "    personalised_model=False\n",
    "    last_activity_model=False\n",
    "    interested_users_model=False\n",
    "    popularity_model_df=None\n",
    "    personalised_model_df=None\n",
    "    last_activity_model_df=None\n",
    "    interested_users_model_df=None\n",
    "    \n",
    "    customer_interactions=[]\n",
    "    service_provider_details=[]\n",
    "    service_details=[]\n",
    "    customer_details=[]\n",
    "    \n",
    "    for y in default_cols :\n",
    "        if y in customer_interactions_total:\n",
    "            customer_interactions.append(y)\n",
    "        if y in service_provider_details_total:\n",
    "            service_provider_details.append(y)\n",
    "        if y in service_details_total:\n",
    "            service_details.append(y)\n",
    "        if y in customer_details_total:    \n",
    "            customer_details.append(y)\n",
    "            \n",
    "    if ('service_id' in service_details) and ('service_name' in service_details) and (len(customer_interactions)!=0):\n",
    "        popularity_model=True\n",
    "    if ('service_id' in service_details) and ('service_name' in service_details) and (len(customer_interactions)!=0) and ('customer_id' in customer_details) :\n",
    "        personalised_model=True\n",
    "        interested_users_model=True\n",
    "        if('purchased' in customer_interactions):\n",
    "            last_activity_model=True\n",
    "        \n",
    "        \n",
    "    if popularity_model==True:    \n",
    "        popularity_model_df = popularity(system_default_df,customer_interactions,topn)\n",
    "        \n",
    "    if (personalised_model==True)  and (interested_users_model==True):\n",
    "        interaction_customer_per_item_df=interaction_customer_per_item(system_default_df,customer_interactions)\n",
    "        tfidf_matrix,dataframe = service_details_vectors(system_default_df,service_details)\n",
    "        user_profiles=build_users_profiles(interaction_customer_per_item_df,dataframe)\n",
    "        if customer_search_id!=None:\n",
    "            personalised_model_df = Hybrid_recommender(customer_search_id,user_profiles,tfidf_matrix,system_default_df,interaction_customer_per_item_df,ignore_previously_interacted_items,ignore_previously_purchased_items,topn)\n",
    "        if customer_search_id!=None and product_search_id!=None and last_activity_model==True:\n",
    "            last_activity_model_df= last_purchase_model(customer_search_id,product_search_id,customer_details,service_details,system_default_df,user_profiles,dataframe,interaction_customer_per_item_df,ignore_previously_interacted_items,ignore_previously_purchased_items,topn)\n",
    "        if product_search_id!=None:\n",
    "            interested_users_model_df= get_interested_users(product_search_id,user_profiles,system_default_df,interaction_customer_per_item_df,dataframe,ignore_previously_interacted_users,ignore_previously_purchased_users,topn)\n",
    "    return popularity_model_df,personalised_model_df,last_activity_model_df,interested_users_model_df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d=job2(2,customer_search_id = -9223121837663643404,product_search_id = -8949113594875411859,topn=10,ignore_previously_interacted_items=True,ignore_previously_purchased_items=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3290087150125937633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1352064057049251194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>548750006199694898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6195985550971229641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9187866633451383747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-299809122140089170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1093393486211919385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-214548742136783496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4778050608932092852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-9047547311469006438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           customer_id\n",
       "0  3290087150125937633\n",
       "1 -1352064057049251194\n",
       "2   548750006199694898\n",
       "3 -6195985550971229641\n",
       "4  9187866633451383747\n",
       "5  -299809122140089170\n",
       "6 -1093393486211919385\n",
       "7  -214548742136783496\n",
       "8  4778050608932092852\n",
       "9 -9047547311469006438"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
